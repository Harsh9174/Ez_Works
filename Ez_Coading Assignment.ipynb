{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4320efdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing all the necessary library\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "\n",
    "# Define a function to parse and structure TMX data\n",
    "def parse_tmx_file(tmx_file):\n",
    "    # Create an ElementTree object from the TMX file\n",
    "    tree = ET.parse(\"C:/Users/Mi/Downloads/ar-en.tmx/ar-en.tmx\")\n",
    "    root = tree.getroot()\n",
    "\n",
    "    # Initialize lists to store English and Arabic sentences\n",
    "    english_sentences = []\n",
    "    arabic_sentences = []\n",
    "\n",
    "    # Iterate through the TMX file to extract translation pairs\n",
    "    for tu in root.findall(\".//tu\"):\n",
    "        english = None\n",
    "        arabic = None\n",
    "\n",
    "        for tuv in tu.findall(\".//tuv\"):\n",
    "            lang = tuv.get(\"{http://www.w3.org/XML/1998/namespace}lang\")\n",
    "\n",
    "            if lang == \"en\":\n",
    "                english = tuv.find(\".//seg\").text\n",
    "            elif lang == \"ar\":\n",
    "                arabic = tuv.find(\".//seg\").text\n",
    "\n",
    "        # Add the translation pair to the respective lists\n",
    "        if english and arabic:\n",
    "            english_sentences.append(english)\n",
    "            arabic_sentences.append(arabic)\n",
    "\n",
    "    return english_sentences, arabic_sentences\n",
    "\n",
    "# Specify the path to your TMX file\n",
    "tmx_file_path = \"C:/Users/Mi/Downloads/ar-en.tmx/ar-en.tmx\"\n",
    "\n",
    "# Call the function to parse and structure the data\n",
    "english_sentences, arabic_sentences = parse_tmx_file(tmx_file_path)\n",
    "\n",
    "# below are the cleaned and structured data in the two lists\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "928b69fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creaing a DataFrame \n",
    "df = pd.DataFrame({'english_sentences':english_sentences,\n",
    "                   'arabic_sentences':arabic_sentences})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36bffd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"english_sentences\"] = df[\"english_sentences\"].str.strip()  # Remove leading/trailing whitespace\n",
    "df[\"arabic_sentences\"] = df[\"arabic_sentences\"].str.strip()    # Remove leading/trailing whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ef6fe68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformation on the text and removing all the unwanted characters\n",
    "def text(text):\n",
    "    L = []\n",
    "    for i in text:\n",
    "        if i.isalpha() or i.isspace():\n",
    "            L.append(i)\n",
    "    return \"\".join(L)\n",
    "for i in df.columns:\n",
    "    df[i] = df[i].apply(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "383e798d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6489"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking he duplicates\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "12d6b8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping all the duplicates\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d8958a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing Sql for Python \n",
    "pip install mysql-connector-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e6cf2059",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# importing Sql library \n",
    "import pandas as pd\n",
    "import mysql.connector\n",
    "\n",
    "# Connect to the MySQL database\n",
    "conn = mysql.connector.connect(host='localhost', user='root', password='Harsh@9174', database='Language')\n",
    "\n",
    "# Creating the database \n",
    "if conn.is_connected():\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(f\"create database if not exists {'Language'}\")\n",
    "    cursor.execute('use Language')\n",
    "    \n",
    "    cursor.execute('''CREATE TABLE IF NOT EXISTS Eng_Arab_Lang (\n",
    "                  english_sentences TEXT,\n",
    "                  arabic_sentences TEXT\n",
    "                )''')\n",
    "    \n",
    "    \n",
    "    # Iterate through the DataFrame rows and insert data into the table\n",
    "    for index, row in df.iterrows():\n",
    "        english_sentence = row['english_sentences']\n",
    "        arabic_sentence = row['arabic_sentences']\n",
    "        \n",
    "        # Define the SQL INSERT statement\n",
    "        insert_query = f\"INSERT INTO Eng_Arab_Lang (english_sentences, arabic_sentences) VALUES ('{english_sentence}', '{arabic_sentence}')\"\n",
    "        \n",
    "        # Execute the INSERT statement\n",
    "        cursor.execute(insert_query)\n",
    "    \n",
    "    # Execute the SELECT statement to retrieve data\n",
    "    cursor.execute('SELECT * FROM Eng_Arab_Lang')\n",
    "    \n",
    "    # Fetch all the rows from the result set\n",
    "    rows = cursor.fetchall()\n",
    "    \n",
    "    # Print the retrieved data\n",
    "    for row in rows:\n",
    "        english_sentence, arabic_sentence = row\n",
    "        print(f'English: {english_sentence}, Arabic: {arabic_sentence}')\n",
    "    \n",
    "    # Commit the changes and close the connection\n",
    "    conn.commit()\n",
    "    conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd14e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the data has been imported to SQL"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
